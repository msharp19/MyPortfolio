@model PortfolioSite.Models.BlogItemModel

@{
    ViewBag.Title = "_CNN";
}

<main role="main-inner-wrapper" class="container">
    <div class="blog-details">
        <article class="post-details" id="post-details">
            <header role="bog-header" class="bog-header text-center">
                <h3><span>19</span> November 2018</h3>
                <h2>
                    A guide in how to work with Convolutional Neural networks in C# and a working example.
                </h2>
                <a class="proj-url" href="https://github.com/msharp19/MyPortfolio/tree/master/PortfolioSite/CNNV2">Git URL<i class="fa fa-external-link" aria-hidden="true"></i></a>
            </header>
            <figure>
                <a href="../images/blog-main-images/cnn.png">
                    <img src="../images/blog-main-images/cnn.png" alt="" class="img-responsive" />
                </a>
            </figure>
            <div class="enter-content">
                <h2>Introduction</h2>
                <p>Convolutional neural networks (CNN's) are deep learning models based off artifical neural networks but which are more suited to recognizing images.</p>
                <p class="left-align">Before we start with CNN's we need to understand how the computer interprets an image. Below we have an image of a man in space above earth how we see it (curtosy of NASA) and below we have a grid which is a simple representation of how a computer sees it. The bounds of the indevidual pixal value are from 0-255, 0 being black and 255 being white making this a value that represents shade (grey scale). The grid below is simplified as computers see in aRGB (alpha, red, blue and green) which each have a value from 0-255. The values below are calculated by taking red, blue and green pixals and dividing them by 3 (the average), we ignore alpha as it is the opacity of an image. For the Mnists example below we use only the greyscale value 0-255 which makes computational time much quicker than if we were to use each value for aRGB which would have 3 times as many values as inputs.</p>
                <figure class="intext-padding">
                    <div class="">
                        <div class="full-length image-center">
                            <a href="../images/cnn/space.jpg">
                                <img id="grid-img" src="../images/cnn/space.jpg" alt="" class="img-responsive inline resize-img" />
                            </a>
                        </div>
                        <p>I chose a picture of space (above) because i wanted a nice gradient between pixal values that is immediatly visible to try to help make my point. The black universe beyond the space man has a value of 0 and we can see where we meet colour (earth) at the bottom of the image we can also clearly see where the space man is in the center of the image. As you might have guessed, for display purposes i have re-sized the grid to 20*20 - the original image above is much larger.</p>
                        <div class="number-table-holder">
                            <table class="number-grid inline"></table>
                        </div>
                    </div>
                    <!--Hidden-->
                    <div style="display:none; ">
                        <img id="grid-img-hidden" src="../images/cnn/space.jpg" width="20" height="20" alt="" class="img-responsive inline" style="display:none;" />
                        <canvas id="rep-img-hidden" class="inline" width="20" height="20" style="display:none; "></canvas>
                    </div>
                </figure>

                <h2>Network Diagram</h2>
                <p>As can be seen below, the architecture is very similar to the regular ANN architecture described in my previous post <a href="../Blog/BlogPost?blogPost=NeuralNetwork">here</a> but it has some additional layers which can be seen on the left.</p>
                <figure class="intext-padding">
                    <a href="../images/blog-main-images/cnn-diagram.png">
                        <img src="../images/blog-main-images/cnn-diagram.png" alt="" class="img-responsive" />
                    </a>
                </figure>
                <h2>Input Layer</h2>
                <p>The input layer takes an array of values that represents an image. Unlike ANN's, the input data for CNN's are volumes. The volumes can consist of a single pixal (avergae of aRGB) - 2 dimensional or multiple dimensions - a volume of each value for RGB. Just like in ANN's the values should be normalized between 0-1, this is done by dividing the pixal by the max possible value - 255.</p>
                <h2>Convolutional Layer</h2>
                <p>CNN's have a convolutional layer where they use filters (kernals) to detect features in an image - edges being an example of this. If you head to my convolution blog found <a href="../Blog/BlogPost?blogPost=Convolution">here</a> i explain what a filter is in much more depth. The filters used in this convolutional layer are set to detect specific features like angled lines or curves. The filter is moved over the whole image and run, a value is then provided representing the confidence of the feature in the respective part of the image. The product sum between the two matrices comes out high if the feature exists and low if it doesn't. There is also a non-linearity layer where we use the ReLU activation function, this helps to introduce non-linearity into our network. If a negative value is passed into the function, 0 is returned and if a possitive value is passed in, it stays the same.</p>
                <h2>Pooling Layer</h2>
                <p>Next there is a pooling layer, this is used to reduce the spatial dimensions of an image although this is done independent of the number of channels - aRGB. It does it by taking the most responsive parts of an image. A window is passed over the image and the maximum value is chosen in the current sample space, the window is then moved to the next set of pixals and the maximum value chosen from that. This significantly reduces redundency and decreases the time taken to train the model. This also helps with reducing overfitting. There is an average pooling in which instead of the maximum value in the sliding window being chosen, the average of the values are selected. This approach doesn't work as well as the max pooling.</p>
                <h2>Dropout Layer</h2>
                <p>We do have another layer that is worth mentioning and that is the dropout layer. This is important as it helps to stop the model overfitting - it does so by dropping out random nodes both hidden and visible.</p>
                <h2>Fully-Connected Layer</h2>
                <p>After the model has run past the pooling layer/dropout layer, we hit the fully connected layer of the network which is explained in one of my other blog posts <a href="../Blog/BlogPost?blogPost=NeuralNetwork">here</a>.</p>
                <h2>Data</h2>
                <p>Data is very important when training CNN's, the more data the better. The issue with having more data is that the time taken to train the overall model increases but this is a good trade off when it comes to accuracy. It is also handy to take your image dataset and duplicate it a few times slightly rotated at angles or flipped. This then increases our chances of being able to classify an image that has been taken in these states - it makes the model more robust and less likely to overfit. It also may be a good idea to do some image pre-processing. If you are classifying images that could potentially have some noise, we can mitigate that with a small bit of processing either through filtering or with an algorithm like entropy cropping. Entropy cropping selects only the subject of the image which removes a lot of the background objects that could potentially fire off our feature detectors in the convolutional layer.</p>
                <h2>Working Example</h2>
                <p>So now i have explained the basics of convolutional neural networks, we will try to make one. BrightWire - is the library used in the following example: <a href="https://github.com/jdermody/brightwire">Git URL<i class="fa fa-external-link" aria-hidden="true"></i></a>. </p>
                <p class="left-align">To build the model for testing, i ran the out the box training method (i have refactored this in one of the code snippits below). This is the model starting to train.</p>
                <figure class="intext-padding">
                    <a href="../images/blog-main-images/train-cnn.png">
                        <img src="../images/blog-main-images/train-cnn.png" alt="" class="img-responsive" />
                    </a>
                </figure>
                <p class="left-align">I left it going for about 4-5 hours to get a reasonable result.</p>
                <figure class="intext-padding">
                    <a href="../images/blog-main-images/train-cnn-2.png">
                        <img src="../images/blog-main-images/train-cnn-2.png" alt="" class="img-responsive" />
                    </a>
                </figure>
                <p class="left-align">I stopped it at which point a model was outputted for use (in the working example below).</p>
                <figure class="intext-padding">
                    <a href="../images/blog-main-images/train-cnn-3.png">
                        <img src="../images/blog-main-images/train-cnn-3.png" alt="" class="img-responsive" />
                    </a>
                </figure>
                <p class="left-align">I had to make a small change to the <a href="https://github.com/jdermody/brightwire">BrightWire</a> project. The change is shown below - i made the Image class in the Mnist class public (was originally internal). The reason for this is that i didnt want to test the model using a file (Mnist.Load()) as i wanted to write my own custom image parsing function. If the Image class is internal, i could not do this. Instead of importing the Nuget version of this library, i added the compiled version of the Brightwire dlls to the project.</p>
                <figure class="intext-padding">
                    <a href="../images/blog-main-images/mnist-change.png">
                        <img src="../images/blog-main-images/mnist-change.png" alt="" class="img-responsive" />
                    </a>
                </figure>
                <p>Below are the methods that build up the model - layers can be added/removed as desired.</p>
                @Html.Partial("_CNNCreateModelMethod")
                <p>The dataset used in the train (below) is the standard Mnist dataset (from Yan LeCun) which can be found <a href="http://yann.lecun.com/exdb/mnist/">here</a>. It is a large collection of handwritten digets from 0-9. Below we train the network and output the model after each iteration.</p>
                @Html.Partial("_CNNTrainMethod")
                <p>Below is the methods to test the network from a raw image (bitmap). As spoken about above, i had to edit the BrightWire project to expose the Mnist.Image object, this is used in the line: var mnist = new Mnist.Image(bytes, 1);. The model has been pre-built and is loaded on request. When returning the prediction we need to format the data as it is in the form of an array, i used the method GetTheLargestPercent which just returns the index of the largest value (predicted number).</p>
                @Html.Partial("_CNNTestMethod")
                <p></p>
                <p class="text-center">Please try the code below!</p>
                <p class="text-center no-margin-bottm">Please also bare in mind that this has been trained with hand-written images not digital. I have chosen a thick brush as i seem to get better results. Also I seem to get better results when the number has a small amount of padding all around (not touching sides of box) <a href="../images/blog-main-images/mnist-handwritten-example.png">Examples</a>.</p>
                <div class="prediction-center">
                    <div id="sketch" class="working-example">
                        <canvas id="paint"></canvas>
                    </div>
                    <div class="inline-block">
                        <div class="predict-box"><span class="predict-box-inner"></span></div>
                    </div>
                    <div id="canvas-controls">
                        <input name="" id="clear-canvas" class="action-button" type="button" value="Clear">
                        <input name="" id="predict" class="action-button" type="button" value="Predict">
                    </div>
                </div>
            </div>
        </article>
        @Html.Partial("_Comments", Model.CommentModel)
    </div>
</main>

<link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
@Scripts.Render("~/Scripts/cnn.js")
@Scripts.Render("~/Scripts/code-block.js")